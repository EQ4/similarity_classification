{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "seaborn.set_style('dark')\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.grid_search\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import pescador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(filename, n_pos=32, n_neg=32):\n",
    "    \n",
    "    data = np.load(filename)\n",
    "    \n",
    "    d = data['X'].shape[1]\n",
    "    \n",
    "    if n_pos is None:\n",
    "        return data['X'], data['Y']\n",
    "    \n",
    "    \n",
    "    positives = np.flatnonzero(data['Y'])\n",
    "    negatives = np.flatnonzero(1-data['Y'])\n",
    "    n_pos = min(n_pos, len(positives))\n",
    "    n_neg = min(n_neg, len(negatives))\n",
    "    \n",
    "    X = np.empty((n_pos + n_neg, d), dtype=np.float32)\n",
    "    Y = np.zeros((n_pos + n_neg), dtype=np.int32)\n",
    "    \n",
    "    if n_pos > 0:\n",
    "        idx_pos = np.random.choice(positives, size=n_pos, replace=True)\n",
    "    \n",
    "        X[:n_pos] = np.take(data['X'], idx_pos, axis=0)\n",
    "        Y[:n_pos] = 1\n",
    "    \n",
    "    if n_neg > 0:\n",
    "        idx_neg = np.random.choice(negatives, size=n_neg, replace=True)\n",
    "        X[n_pos:] = np.take(data['X'], idx_neg, axis=0)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_batch(files, n_pos=32, n_neg=32):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for fn in files:\n",
    "        _x, _y = load_file(fn, n_pos=n_pos, n_neg=n_neg)\n",
    "        if _x.shape[0] == 0:\n",
    "            continue\n",
    "        X.append(_x)\n",
    "        Y.append(_y)\n",
    "        \n",
    "    X = np.concatenate(X, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEG_TO_POS = 156 # salami\n",
    "#NEG_TO_POS = 157 # Isophonics\n",
    "N_POS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('../data/labeled_features/SALAMI_*_beats.npz'))\n",
    "#files = sorted(glob.glob('../data/labeled_features/Isophonics_*_beats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesplitter = sklearn.cross_validation.ShuffleSplit(len(files), n_iter=1, test_size=0.80, random_state=5)\n",
    "_files = np.asarray(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "-- Epoch 1\n",
      "Norm: 499.29, NNZs: 639, Bias: -604.606038, T: 101354, Avg. loss: 5.379499\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 496.39, NNZs: 598, Bias: -603.536065, T: 202708, Avg. loss: 4.220530\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 494.98, NNZs: 576, Bias: -602.746986, T: 304062, Avg. loss: 3.789710\n",
      "Total training time: 2.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 494.17, NNZs: 559, Bias: -602.053147, T: 405416, Avg. loss: 3.556189\n",
      "Total training time: 3.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 493.59, NNZs: 551, Bias: -601.483058, T: 506770, Avg. loss: 3.406149\n",
      "Total training time: 4.55 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 550.30, NNZs: 660, Bias: -658.775751, T: 101356, Avg. loss: 6.067528\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 546.70, NNZs: 635, Bias: -658.066880, T: 202712, Avg. loss: 4.792722\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 544.93, NNZs: 619, Bias: -657.459709, T: 304068, Avg. loss: 4.313219\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 543.81, NNZs: 612, Bias: -656.965424, T: 405424, Avg. loss: 4.050481\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 542.98, NNZs: 605, Bias: -656.576761, T: 506780, Avg. loss: 3.879912\n",
      "Total training time: 4.40 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 561.15, NNZs: 670, Bias: -680.659155, T: 101356, Avg. loss: 6.152207\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 557.81, NNZs: 646, Bias: -679.932613, T: 202712, Avg. loss: 4.797083\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 556.12, NNZs: 626, Bias: -679.375692, T: 304068, Avg. loss: 4.292808\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 555.04, NNZs: 616, Bias: -678.900357, T: 405424, Avg. loss: 4.019536\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 554.31, NNZs: 609, Bias: -678.474632, T: 506780, Avg. loss: 3.844017\n",
      "Total training time: 4.44 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.61, NNZs: 924, Bias: -453.003794, T: 101354, Avg. loss: 2.702301\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.05, NNZs: 924, Bias: -449.739541, T: 202708, Avg. loss: 2.144598\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.22, NNZs: 924, Bias: -447.794116, T: 304062, Avg. loss: 1.952681\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24.28, NNZs: 924, Bias: -446.408719, T: 405416, Avg. loss: 1.854286\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.28, NNZs: 924, Bias: -445.343388, T: 506770, Avg. loss: 1.794101\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.91, NNZs: 924, Bias: -485.006478, T: 101356, Avg. loss: 3.148288\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.61, NNZs: 924, Bias: -481.637803, T: 202712, Avg. loss: 2.431200\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.10, NNZs: 924, Bias: -479.689795, T: 304068, Avg. loss: 2.186097\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.54, NNZs: 924, Bias: -478.258804, T: 405424, Avg. loss: 2.062207\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.28, NNZs: 924, Bias: -477.185271, T: 506780, Avg. loss: 1.986309\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.16, NNZs: 924, Bias: -452.882245, T: 101356, Avg. loss: 2.583688\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.97, NNZs: 924, Bias: -449.590666, T: 202712, Avg. loss: 2.087324\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.43, NNZs: 924, Bias: -447.711681, T: 304068, Avg. loss: 1.914980\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.43, NNZs: 924, Bias: -446.349065, T: 405424, Avg. loss: 1.826872\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.41, NNZs: 924, Bias: -445.299151, T: 506780, Avg. loss: 1.773052\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 28.00, NNZs: 754, Bias: -439.758113, T: 101354, Avg. loss: 2.690326\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 27.04, NNZs: 764, Bias: -436.398427, T: 202708, Avg. loss: 2.106372\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.16, NNZs: 783, Bias: -434.425737, T: 304062, Avg. loss: 1.905823\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.93, NNZs: 790, Bias: -433.046239, T: 405416, Avg. loss: 1.802260\n",
      "Total training time: 2.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.94, NNZs: 794, Bias: -431.968289, T: 506770, Avg. loss: 1.739153\n",
      "Total training time: 3.74 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.03, NNZs: 774, Bias: -471.044504, T: 101356, Avg. loss: 2.896664\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.26, NNZs: 799, Bias: -467.640220, T: 202712, Avg. loss: 2.273497\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.99, NNZs: 810, Bias: -465.657897, T: 304068, Avg. loss: 2.058968\n",
      "Total training time: 2.22 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.00, NNZs: 811, Bias: -464.248690, T: 405424, Avg. loss: 1.949860\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.35, NNZs: 824, Bias: -463.134865, T: 506780, Avg. loss: 1.883495\n",
      "Total training time: 3.67 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.86, NNZs: 757, Bias: -436.931184, T: 101356, Avg. loss: 2.555666\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.89, NNZs: 780, Bias: -433.662447, T: 202712, Avg. loss: 2.040232\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 25.69, NNZs: 788, Bias: -431.754272, T: 304068, Avg. loss: 1.861705\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.60, NNZs: 792, Bias: -430.393332, T: 405424, Avg. loss: 1.770432\n",
      "Total training time: 3.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.65, NNZs: 793, Bias: -429.332019, T: 506780, Avg. loss: 1.714472\n",
      "Total training time: 3.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 191.00, NNZs: 96, Bias: -102.381213, T: 101354, Avg. loss: 0.758610\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 191.12, NNZs: 69, Bias: -101.812853, T: 202708, Avg. loss: 0.640388\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 191.18, NNZs: 63, Bias: -101.475404, T: 304062, Avg. loss: 0.610988\n",
      "Total training time: 2.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 191.22, NNZs: 55, Bias: -101.236236, T: 405416, Avg. loss: 0.601447\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 191.25, NNZs: 50, Bias: -101.050479, T: 506770, Avg. loss: 0.598958\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 216.99, NNZs: 137, Bias: -133.309343, T: 101356, Avg. loss: 1.150362\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 217.12, NNZs: 103, Bias: -132.781047, T: 202712, Avg. loss: 0.880250\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 217.21, NNZs: 85, Bias: -132.446752, T: 304068, Avg. loss: 0.795938\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 217.27, NNZs: 75, Bias: -132.206815, T: 405424, Avg. loss: 0.758275\n",
      "Total training time: 3.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 217.32, NNZs: 74, Bias: -132.020164, T: 506780, Avg. loss: 0.738485\n",
      "Total training time: 3.91 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 206.24, NNZs: 148, Bias: -112.236609, T: 101356, Avg. loss: 0.885775\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 206.33, NNZs: 104, Bias: -111.783078, T: 202712, Avg. loss: 0.680352\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 206.40, NNZs: 84, Bias: -111.479107, T: 304068, Avg. loss: 0.613625\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 206.45, NNZs: 78, Bias: -111.252684, T: 405424, Avg. loss: 0.581565\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 206.50, NNZs: 68, Bias: -111.071485, T: 506780, Avg. loss: 0.563830\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4.46, NNZs: 924, Bias: -95.209451, T: 101354, Avg. loss: 0.648248\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.43, NNZs: 924, Bias: -94.814310, T: 202708, Avg. loss: 0.502232\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.44, NNZs: 924, Bias: -94.578487, T: 304062, Avg. loss: 0.452961\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.36, NNZs: 924, Bias: -94.416302, T: 405416, Avg. loss: 0.427853\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.41, NNZs: 924, Bias: -94.285791, T: 506770, Avg. loss: 0.412854\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4.09, NNZs: 924, Bias: -83.859957, T: 101356, Avg. loss: 0.627938\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.00, NNZs: 924, Bias: -83.480700, T: 202712, Avg. loss: 0.469274\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.01, NNZs: 924, Bias: -83.252662, T: 304068, Avg. loss: 0.415893\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.96, NNZs: 924, Bias: -83.094304, T: 405424, Avg. loss: 0.388821\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.01, NNZs: 924, Bias: -82.967093, T: 506780, Avg. loss: 0.372568\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 3.83, NNZs: 924, Bias: -82.333813, T: 101356, Avg. loss: 0.503428\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.80, NNZs: 924, Bias: -81.961444, T: 202712, Avg. loss: 0.403744\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.83, NNZs: 924, Bias: -81.740710, T: 304068, Avg. loss: 0.369928\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.81, NNZs: 924, Bias: -81.585674, T: 405424, Avg. loss: 0.352698\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.73, NNZs: 924, Bias: -81.468485, T: 506780, Avg. loss: 0.342080\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.45, NNZs: 557, Bias: -96.538166, T: 101354, Avg. loss: 0.739813\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.46, NNZs: 587, Bias: -95.978449, T: 202708, Avg. loss: 0.577967\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.47, NNZs: 611, Bias: -95.654290, T: 304062, Avg. loss: 0.521973\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.47, NNZs: 629, Bias: -95.424811, T: 405416, Avg. loss: 0.491909\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.48, NNZs: 640, Bias: -95.247858, T: 506770, Avg. loss: 0.473879\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.87, NNZs: 506, Bias: -80.084884, T: 101356, Avg. loss: 0.537187\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.89, NNZs: 532, Bias: -79.539939, T: 202712, Avg. loss: 0.440469\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.79, NNZs: 559, Bias: -79.228832, T: 304068, Avg. loss: 0.404348\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5.80, NNZs: 569, Bias: -79.004992, T: 405424, Avg. loss: 0.386407\n",
      "Total training time: 3.21 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.76, NNZs: 572, Bias: -78.834709, T: 506780, Avg. loss: 0.374432\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.07, NNZs: 533, Bias: -86.832807, T: 101356, Avg. loss: 0.551666\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.06, NNZs: 566, Bias: -86.298249, T: 202712, Avg. loss: 0.456699\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.95, NNZs: 581, Bias: -85.995530, T: 304068, Avg. loss: 0.421946\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5.93, NNZs: 591, Bias: -85.778017, T: 405424, Avg. loss: 0.404344\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.94, NNZs: 604, Bias: -85.607793, T: 506780, Avg. loss: 0.393768\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 73.34, NNZs: 0, Bias: -12.497266, T: 101354, Avg. loss: 0.119317\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.34, NNZs: 0, Bias: -12.440077, T: 202708, Avg. loss: 0.111685\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 73.34, NNZs: 0, Bias: -12.406127, T: 304062, Avg. loss: 0.109020\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 73.34, NNZs: 0, Bias: -12.382045, T: 405416, Avg. loss: 0.107628\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73.34, NNZs: 0, Bias: -12.363486, T: 506770, Avg. loss: 0.106758\n",
      "Total training time: 3.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 77.15, NNZs: 0, Bias: -13.452006, T: 101356, Avg. loss: 0.131622\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 77.15, NNZs: 0, Bias: -13.394294, T: 202712, Avg. loss: 0.121884\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 77.15, NNZs: 0, Bias: -13.360574, T: 304068, Avg. loss: 0.118517\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 77.15, NNZs: 0, Bias: -13.336668, T: 405424, Avg. loss: 0.116775\n",
      "Total training time: 3.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 77.15, NNZs: 0, Bias: -13.318014, T: 506780, Avg. loss: 0.115694\n",
      "Total training time: 3.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 70.07, NNZs: 0, Bias: -12.085832, T: 101356, Avg. loss: 0.113808\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 70.07, NNZs: 0, Bias: -12.027704, T: 202712, Avg. loss: 0.107270\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 70.07, NNZs: 0, Bias: -11.993894, T: 304068, Avg. loss: 0.104969\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 70.07, NNZs: 0, Bias: -11.969895, T: 405424, Avg. loss: 0.103760\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 70.07, NNZs: 0, Bias: -11.951184, T: 506780, Avg. loss: 0.102999\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.59, NNZs: 924, Bias: -14.713363, T: 101354, Avg. loss: 0.096213\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 924, Bias: -14.671434, T: 202708, Avg. loss: 0.080556\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.57, NNZs: 924, Bias: -14.647280, T: 304062, Avg. loss: 0.075248\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.58, NNZs: 924, Bias: -14.629710, T: 405416, Avg. loss: 0.072630\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.58, NNZs: 924, Bias: -14.616271, T: 506770, Avg. loss: 0.071025\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.51, NNZs: 924, Bias: -13.498382, T: 101356, Avg. loss: 0.082185\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.52, NNZs: 924, Bias: -13.458243, T: 202712, Avg. loss: 0.071819\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.52, NNZs: 924, Bias: -13.435344, T: 304068, Avg. loss: 0.068283\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.52, NNZs: 924, Bias: -13.418937, T: 405424, Avg. loss: 0.066497\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 924, Bias: -13.406519, T: 506780, Avg. loss: 0.065386\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.47, NNZs: 924, Bias: -12.338294, T: 101356, Avg. loss: 0.075721\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.45, NNZs: 924, Bias: -12.302909, T: 202712, Avg. loss: 0.065721\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.46, NNZs: 924, Bias: -12.281595, T: 304068, Avg. loss: 0.062411\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.46, NNZs: 924, Bias: -12.266605, T: 405424, Avg. loss: 0.060739\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 924, Bias: -12.255564, T: 506780, Avg. loss: 0.059670\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 0, Bias: -16.580538, T: 101354, Avg. loss: 0.171070\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 0, Bias: -16.523373, T: 202708, Avg. loss: 0.154601\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 0, Bias: -16.489603, T: 304062, Avg. loss: 0.148991\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.04, NNZs: 0, Bias: -16.465689, T: 405416, Avg. loss: 0.146126\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.04, NNZs: 0, Bias: -16.447079, T: 506770, Avg. loss: 0.144373\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 0, Bias: -13.750019, T: 101356, Avg. loss: 0.169980\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 0, Bias: -13.692428, T: 202712, Avg. loss: 0.142309\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 0, Bias: -13.658339, T: 304068, Avg. loss: 0.132964\n",
      "Total training time: 2.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.04, NNZs: 0, Bias: -13.634370, T: 405424, Avg. loss: 0.128231\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.04, NNZs: 0, Bias: -13.615706, T: 506780, Avg. loss: 0.125357\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 0, Bias: -10.425802, T: 101356, Avg. loss: 0.104241\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 0, Bias: -10.368385, T: 202712, Avg. loss: 0.095564\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 0, Bias: -10.334589, T: 304068, Avg. loss: 0.092552\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.04, NNZs: 0, Bias: -10.310663, T: 405424, Avg. loss: 0.090987\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.04, NNZs: 0, Bias: -10.292032, T: 506780, Avg. loss: 0.090012\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.75, NNZs: 0, Bias: -2.332565, T: 101354, Avg. loss: 0.119910\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.75, NNZs: 0, Bias: -2.386605, T: 202708, Avg. loss: 0.114808\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.75, NNZs: 0, Bias: -2.416901, T: 304062, Avg. loss: 0.112091\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.75, NNZs: 0, Bias: -2.437843, T: 405416, Avg. loss: 0.110271\n",
      "Total training time: 3.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.75, NNZs: 0, Bias: -2.453774, T: 506770, Avg. loss: 0.108917\n",
      "Total training time: 3.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 12.09, NNZs: 0, Bias: -2.353432, T: 101356, Avg. loss: 0.117905\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.09, NNZs: 0, Bias: -2.406339, T: 202712, Avg. loss: 0.113039\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.09, NNZs: 0, Bias: -2.436022, T: 304068, Avg. loss: 0.110442\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.09, NNZs: 0, Bias: -2.456558, T: 405424, Avg. loss: 0.108700\n",
      "Total training time: 2.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.09, NNZs: 0, Bias: -2.472183, T: 506780, Avg. loss: 0.107402\n",
      "Total training time: 3.66 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 13.31, NNZs: 0, Bias: -2.331846, T: 101356, Avg. loss: 0.119945\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.31, NNZs: 0, Bias: -2.385881, T: 202712, Avg. loss: 0.114865\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.31, NNZs: 0, Bias: -2.416193, T: 304068, Avg. loss: 0.112155\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.31, NNZs: 0, Bias: -2.437129, T: 405424, Avg. loss: 0.110338\n",
      "Total training time: 3.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.31, NNZs: 0, Bias: -2.453074, T: 506780, Avg. loss: 0.108985\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.750801, T: 101354, Avg. loss: 0.089581\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.785783, T: 202708, Avg. loss: 0.086273\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.805648, T: 304062, Avg. loss: 0.084737\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.819489, T: 405416, Avg. loss: 0.083769\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.830088, T: 506770, Avg. loss: 0.083073\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 924, Bias: -2.472633, T: 101356, Avg. loss: 0.108109\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 924, Bias: -2.519230, T: 202712, Avg. loss: 0.103359\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.03, NNZs: 924, Bias: -2.545485, T: 304068, Avg. loss: 0.101021\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.563693, T: 405424, Avg. loss: 0.099504\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.577578, T: 506780, Avg. loss: 0.098396\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.769538, T: 101356, Avg. loss: 0.088802\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.803774, T: 202712, Avg. loss: 0.085585\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.823223, T: 304068, Avg. loss: 0.084101\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.836778, T: 405424, Avg. loss: 0.083168\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 924, Bias: -2.847149, T: 506780, Avg. loss: 0.082498\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.476735, T: 101354, Avg. loss: 0.107860\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.523478, T: 202708, Avg. loss: 0.103711\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.549811, T: 304062, Avg. loss: 0.101564\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.568066, T: 405416, Avg. loss: 0.100141\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.581994, T: 506770, Avg. loss: 0.099086\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.524616, T: 101356, Avg. loss: 0.104299\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.569156, T: 202712, Avg. loss: 0.100411\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.594302, T: 304068, Avg. loss: 0.098421\n",
      "Total training time: 2.44 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.611731, T: 405424, Avg. loss: 0.097106\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.625028, T: 506780, Avg. loss: 0.096135\n",
      "Total training time: 4.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.456582, T: 101356, Avg. loss: 0.108875\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.504345, T: 202712, Avg. loss: 0.104897\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.531223, T: 304068, Avg. loss: 0.102775\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.549840, T: 405424, Avg. loss: 0.101349\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 0, Bias: -2.564030, T: 506780, Avg. loss: 0.100286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    6.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 183.52, NNZs: 77, Bias: -94.220505, T: 152033, Avg. loss: 0.602323\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 183.65, NNZs: 55, Bias: -93.634905, T: 304066, Avg. loss: 0.526609\n",
      "Total training time: 2.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 183.72, NNZs: 46, Bias: -93.296836, T: 456099, Avg. loss: 0.508367\n",
      "Total training time: 4.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 183.77, NNZs: 43, Bias: -93.056306, T: 608132, Avg. loss: 0.503644\n",
      "Total training time: 5.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 183.80, NNZs: 39, Bias: -92.869068, T: 760165, Avg. loss: 0.503335\n",
      "Total training time: 7.15 seconds.\n",
      "Loading testing data..."
     ]
    }
   ],
   "source": [
    "for trainf, testf in filesplitter:\n",
    "    \n",
    "    print 'Loading training data...'\n",
    "    X_train, Y_train = load_batch([_files[_] for _ in trainf],\n",
    "                                 n_pos=N_POS,\n",
    "                                 n_neg=NEG_TO_POS * N_POS)\n",
    "    \n",
    "    _model = sklearn.grid_search.GridSearchCV(sklearn.linear_model.SGDClassifier(loss='log', verbose=1),\n",
    "                                             {'alpha': np.logspace(-3, 1, num=4, endpoint=False),\n",
    "                                             'penalty': ['l1', 'l2', 'elasticnet']},\n",
    "                                             n_jobs=1, verbose=1)\n",
    "    \n",
    "    #_model = sklearn.grid_search.GridSearchCV(sklearn.ensemble.RandomForestClassifier(),\n",
    "    #                                         {'max_depth': np.arange(2, 11)},\n",
    "    #                                         n_jobs=3, verbose=1)\n",
    "    \n",
    "    feature = sklearn.preprocessing.StandardScaler()\n",
    "    model = sklearn.pipeline.Pipeline([('scaler', feature), ('predictor', _model)])\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    print 'Loading testing data...'\n",
    "    X_test, Y_test = load_batch([_files[_] for _ in testf],\n",
    "                                n_pos=None,\n",
    "                                n_neg=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = model.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = model.steps[1][1].best_estimator_.coef_[0]\n",
    "w = w.reshape((-1, 84))\n",
    "plt.imshow(w.T, aspect='auto', interpolation='none', cmap='coolwarm', origin='lower')\n",
    "plt.ylabel('CQT bin')\n",
    "plt.xlabel('Context position')\n",
    "plt.title('$w$')\n",
    "plt.xticks(np.arange(5), np.arange(-2, 3))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sklearn.metrics.classification_report(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = [model.predict(xt) for xt in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_proba = np.concatenate([model.predict_proba(xt) for xt in X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = np.concatenate(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sklearn.metrics.classification_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump({'model': model, 'dataset': 'salami_beat'},\n",
    "            open('../data/similarity_model_salami_beat_bias.pickle', 'w'))\n",
    "#pickle.dump({'model': model, 'dataset': 'isophonics_beat'},\n",
    "            #open('../data/similarity_model_isophonics_beat_bias_est.pickle', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrains2 = np.mean(X_train**2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtests2 = np.mean(X_test**2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seaborn.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:   11.5s\n",
      "[Parallel(n_jobs=3)]: Done  21 out of  25 | elapsed:  1.5min remaining:   17.3s\n",
      "[Parallel(n_jobs=3)]: Done  25 out of  25 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelDensity(algorithm='auto', atol=0, bandwidth=1.0, breadth_first=True,\n",
       "       kernel='gaussian', leaf_size=40, metric='euclidean',\n",
       "       metric_params=None, rtol=0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=3,\n",
       "       param_grid={'bandwidth': array([ 0.1  ,  0.325,  0.55 ,  0.775,  1.   ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KDE_pos = sklearn.grid_search.GridSearchCV(sklearn.neighbors.KernelDensity(),\n",
    "                                           {'bandwidth': np.linspace(0.1, 1.0, 5)},\n",
    "                                           verbose=1,\n",
    "                                           n_jobs=3,\n",
    "                                           cv=5)\n",
    "KDE_pos.fit(Xtrains2[Y_train > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:   14.5s\n",
      "[Parallel(n_jobs=3)]: Done  11 out of  15 | elapsed:  1.2min remaining:   25.4s\n",
      "[Parallel(n_jobs=3)]: Done  15 out of  15 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelDensity(algorithm='auto', atol=0, bandwidth=1.0, breadth_first=True,\n",
       "       kernel='gaussian', leaf_size=40, metric='euclidean',\n",
       "       metric_params=None, rtol=0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=3,\n",
       "       param_grid={'bandwidth': array([ 0.1 ,  0.55,  1.  ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KDE_neg = sklearn.grid_search.GridSearchCV(sklearn.neighbors.KernelDensity(),\n",
    "                                           {'bandwidth': np.linspace(0.1, 1.0, 3)},\n",
    "                                           verbose=1,\n",
    "                                           n_jobs=3,\n",
    "                                           cv=5)\n",
    "KDE_neg.fit(Xtrains2[Y_train < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_kde = (KDE_pos.best_estimator_.score_samples(Xtests2) >\n",
    "              KDE_neg.best_estimator_.score_samples(Xtests2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.68      0.67    143276\n",
      "          1       0.58      0.56      0.57    114243\n",
      "\n",
      "avg / total       0.62      0.62      0.62    257519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.classification_report(Y_test[:len(Y_pred_kde)], Y_pred_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-d8507f42514d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrains2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mY_train\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Positive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrains2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mY_train\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Negative'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax, cumulative, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[0mbivariate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[0mbivariate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAECCAYAAAAFL5eMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVnkIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4338b12fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.kdeplot(np.log(Xtrains2[Y_train > 0]), shade=True, label='Positive')\n",
    "seaborn.kdeplot(np.log(Xtrains2[Y_train < 1]), shade=True, label='Negative')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
